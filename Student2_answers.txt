
**Student Name:** James Bond
**Course:** AI 201: Foundations of Artificial Intelligence
**Exam:** Midterm Exam

---

**Answer 1: Search Algorithms**

Breadth-First Search (BFS) and Depth-First Search (DFS) are fundamental uninformed search algorithms, meaning they explore the search space without using any domain-specific knowledge about how close a state might be to the goal. Their primary difference lies in their exploration strategy. BFS explores layer by layer, using a queue (FIFO) to manage nodes. It examines all nodes at depth 'd' before moving to depth 'd+1'. In contrast, DFS explores as deeply as possible along one path before backtracking, typically using a stack (LIFO).

Regarding their properties, BFS is complete, meaning it's guaranteed to find a solution if one exists. It's also optimal if path costs are uniform (e.g., each step costs 1), as it finds the shallowest goal node first. However, its space complexity is a major drawback, requiring O(b^d) memory (where 'b' is the branching factor and 'd' is the depth of the solution), as it stores all nodes at the current depth frontier. Its time complexity is also O(b^d).

DFS, on the other hand, has a much lower space complexity, typically O(bm) (where 'm' is the maximum depth of the search space), as it only needs to store the current path and its siblings. However, it's not complete in infinite spaces or spaces with cycles unless cycle detection is implemented or depth is limited. Furthermore, DFS is not optimal; it might find a very deep solution quickly while a much shallower one exists elsewhere. Its time complexity can be O(b^m) in the worst case.

A scenario where BFS is preferable is finding the shortest path in terms of steps between two users in a social network. BFS guarantees finding the connection with the fewest links. DFS might be more suitable for solving a deep puzzle like a complex maze where any solution path is acceptable, and memory constraints are tight, making BFS's memory usage prohibitive.

**Answer 2: Informed Search and Heuristics**

A heuristic function, denoted h(n), is a core component of informed search algorithms like A*. Its purpose is to estimate the cost of reaching the goal state from a given state 'n'. Unlike uninformed search, which explores blindly, informed search uses this heuristic estimate to guide the exploration towards nodes that appear to be closer to the goal, potentially finding a solution much more efficiently. The heuristic provides domain-specific knowledge to the search algorithm, making it "informed."

Two crucial properties for heuristics, especially in the context of A*, are admissibility and consistency. A heuristic h(n) is admissible if it *never overestimates* the actual cost to reach the goal from node n. That is, h(n) ≤ h*(n), where h*(n) is the true lowest cost from n to the goal. A heuristic is consistent (or monotonic) if, for every node n and every successor n' generated by action a, the estimated cost from n is no greater than the step cost of getting to n' plus the estimated cost from n': h(n) ≤ cost(n, a, n') + h(n'). Consistency implies admissibility (assuming h(goal)=0).

Admissibility is vital for A* search because it guarantees optimality. If the heuristic is admissible, A* will always find the least-cost path to the goal, provided one exists. It ensures that the algorithm doesn't prematurely discard a path that seems expensive based on the heuristic but is actually optimal. Using a more informed (higher value, but still admissible) heuristic generally improves A*'s performance by reducing the number of nodes expanded, focusing the search more effectively. However, a highly informed heuristic might be more computationally expensive to calculate at each step. A less informed heuristic (e.g., h(n)=0, which makes A* behave like Dijkstra's or Uniform Cost Search) is often easier to compute but leads to exploring many more nodes, potentially decreasing overall efficiency.

**Answer 3: Knowledge Representation**

Two distinct methods for representing knowledge in AI are Semantic Networks and Production Rules.

Semantic Networks represent knowledge as a graph structure. Nodes in the graph typically represent objects, concepts, or events, while the links (arcs) between nodes represent relationships between them. These links are usually labeled to specify the type of relationship (e.g., "is-a", "has-part", "color"). For example, a node 'Bird' might have an "is-a" link to 'Animal' and a "has-part" link to 'Wings'. One strength of semantic networks is their intuitive, visual nature, making relationships easy to grasp. They also naturally support property inheritance through "is-a" links (e.g., if a Bird "can fly", and a Robin "is-a" Bird, then a Robin "can fly"). However, weaknesses include potential ambiguity in link meanings without a strict formalism, and performing complex logical inference can be difficult and computationally inefficient. The meaning can sometimes depend heavily on the program using the network.

Production Rules, often used in expert systems, represent knowledge as condition-action pairs, typically in an "IF <condition> THEN <action>" format. The <condition> part specifies facts or patterns that must be present in the current working memory (the system's current state description), and the <action> part specifies operations to perform, such as adding a new fact, modifying existing ones, or executing an external procedure. A system using production rules usually consists of a rule base (the set of IF-THEN rules), a working memory, and an inference engine that decides which applicable rule to fire. Strengths include modularity (rules can often be added or removed independently), natural expression of procedural knowledge, and relative ease of explanation. Weaknesses include potential inefficiency when the number of rules becomes large (conflict resolution can be complex), difficulty representing descriptive knowledge naturally, and the possibility of unforeseen interactions between rules.

**Answer 4: Logic and Inference**

Logical inference is fundamental to AI reasoning because it provides a formal mechanism for deriving new knowledge (conclusions) from existing knowledge (premises or facts stored in a knowledge base, KB). Instead of explicitly storing every possible fact, an AI system can use inference rules to deduce implicit information, enabling it to reason about its world, make decisions, and solve problems more effectively.

Logical entailment (written KB |= α) defines the core idea: a knowledge base KB entails a sentence α if and only if α is true in all possible worlds where KB is true. In other words, α is a guaranteed logical consequence of KB.

Modus Ponens is a classic, fundamental inference rule. Its logical form is: If we know P is true, and we know that P implies Q (P ⇒ Q), then we can infer that Q is true. Formally: (P, P ⇒ Q) |= Q. For a simple example: If the KB contains "It is raining" (P) and the rule "IF it is raining THEN the street is wet" (P ⇒ Q), Modus Ponens allows the system to infer "The street is wet" (Q).

An inference procedure is sound if it only derives sentences that are logically entailed by the knowledge base. It doesn't invent conclusions that aren't justified. A procedure is complete if it can derive *every* sentence that is logically entailed by the knowledge base. Soundness is crucial because deriving false conclusions makes the system unreliable. Completeness is desirable because it means the system can discover all true consequences of its knowledge. However, these goals can conflict, especially in more expressive logics like First-Order Logic. Achieving completeness might require computationally intractable procedures, forcing practical AI systems to sometimes use sound but incomplete inference methods that are efficient but might miss some valid conclusions.

**Answer 5: Planning**

Classical planning in AI deals with finding a sequence of actions that transforms an initial state of the world into a desired goal state. It operates under several simplifying assumptions: the world is deterministic (actions have predictable outcomes), fully observable (the agent knows the complete state), static (no external changes occur except by the agent's actions), and time is discrete. The focus is purely on generating the *sequence* of actions, not necessarily optimizing execution time or resource usage beyond finding a valid plan.

The STRIPS (Stanford Research Institute Problem Solver) representation is a common way to formalize classical planning problems. It defines:
1.  **States:** Represented as conjunctions of positive literals (atomic facts that are true). Anything not listed is assumed false (Closed World Assumption).
2.  **Actions/Operators:** Defined by:
    *   *Preconditions:* A set of literals that must be true in the current state for the action to be executable.
    *   *Effects:* A set of literals describing how the state changes when the action is executed. Effects typically include an *add list* (literals that become true) and a *delete list* (literals that become false).
3.  **Initial State:** A complete description of the starting state, given as a set of true literals.
4.  **Goal Specification:** A set of literals that must be true in the final state. It might be a partial description; other aspects of the final state don't matter.

Searching in the state space involves treating states as nodes in a graph and actions as transitions between states. The planner searches from the initial state forward (or goal state backward) until a state satisfying the goal is found. Searching in the plan space, conversely, works on partial plans. It starts with a minimal plan (e.g., just start and finish nodes) and searches by adding actions, ordering steps, and resolving conflicts (like one action deleting another's precondition) until a complete, correct plan is formed.

A major challenge making planning computationally difficult is the combinatorial explosion. The number of possible states and, more critically, the number of possible sequences of actions grows exponentially with the number of objects and available actions, making exhaustive search infeasible for non-trivial problems. This is often referred to as the "curse of dimensionality" in the context of the state space size.
